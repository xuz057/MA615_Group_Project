---
title: "Textmining exercise"
author: "Xuan,Megha, Yifu,Sky"
date: "November 4, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##SCRAPING DATA FROM https://correlaid.org/blog/

```{r}
#get text from the blog
# load packages
library(rvest)
library(tidyverse)
#read text
blog1 <- read_html("https://correlaid.org/blog/posts/point-pattern-analysis")
blog2 <- read_html("https://correlaid.org/blog/posts/tic-tac-toe-ai")
read_blog1 <- blog1 %>%
 html_nodes("p") %>%
 html_text()
read_blog2 <- blog2 %>%
 html_nodes("p") %>%
 html_text()
```

## Chapter 1: GET A TIDY TEXT FORMAT
```{r}
#make raw text as data frame
library(dplyr)
text1 <- data_frame(line = 1:37, text = read_blog1)
text2 <- data_frame(line = 1:24, text = read_blog2)

#remove empty lines
text1 <- text1 %>% filter(text != "")
text2 <- text2 %>% filter(text != "")

#a token per row
library(tidytext)
text1 <-text1 %>%unnest_tokens(word,text)
text2 <-text2 %>%unnest_tokens(word,text)

library(stringr)
#get rid of any non-characters
text1 <- text1 %>%mutate(word = str_extract(word,"[a-z']+"))
text1 <-na.omit(text1)

text2 <- text2 %>%mutate(word = str_extract(word,"[a-z']+"))
text2 <-na.omit(text2)

#get rid of stop-words
text1<- text1 %>% anti_join(stop_words)
text2<- text2 %>% anti_join(stop_words)

#word count
library(ggplot2)
text1 %>%
count(word, sort = TRUE)%>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +geom_col() +xlab(NULL) +coord_flip()

text2 %>%
count(word, sort = TRUE)%>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +geom_col() +xlab(NULL) +coord_flip()

```

(add comments here: what do we see from word count?)


```{r}
#Comparing the word frequencies of text1 & text2
library(tidyr)
frequency <- bind_rows(mutate(text1, author = "Lisa"),
                       mutate(text2, author = "Johannes")) %>%
  count(author, word) %>%
  group_by(author) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(author, proportion)

library(scales)
# expect a warning about rows with missing values being removed
ggplot(frequency, aes(x = Johannes, y =Lisa, color = abs(Lisa - Johannes))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  theme(legend.position="none") 


```
(add comments here)

##Chapter 2: Sentiment Analysis With Tidy Data

```{r}
text_total <- bind_rows(mutate(text1, author = "Lisa"),
                       mutate(text2, author = "Johannes")) 
library(tidyr)

sentiment <- text_total %>%
  inner_join(get_sentiments("bing")) %>%
  count(author, index = line %/% 2, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

library(ggplot2)
ggplot(sentiment, aes(index, sentiment, fill = author)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~author, ncol = 2, scales = "free_x")

```

(add comments here)

#Comparing the three sentiment dictionaries

```{r}
#use text1 here as an example
afinn <- text1 %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = line %/% 2) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(text1 %>% 
                            inner_join(get_sentiments("bing")) %>%
                            mutate(method = "Bing et al."),
                          text1 %>% 
                            inner_join(get_sentiments("nrc") %>% 
                                         filter(sentiment %in% c("positive", 
                                                                 "negative"))) %>%
                            mutate(method = "NRC")) %>%
  count(method, index = line %/% 2, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

(add comments here)
##Most common positive and negative words
```{r}
#use text2 here as an example

bing_word_counts <- text2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(2) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
```

#Word Cloud
```{r}
library(wordcloud)
text1 %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
text2 %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```